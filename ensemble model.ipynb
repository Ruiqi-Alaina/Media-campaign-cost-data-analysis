{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90cae5e7-938b-4820-bd20-bc9012e34a02",
   "metadata": {},
   "source": [
    "# Custom Jobs with custom container in Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3afab248-0ea4-43fb-ba4c-90164ec39f94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install or import packages\n",
    "try:\n",
    "    import google.cloud.service_usage_v1\n",
    "except ImportError:\n",
    "    print('You need to pip install google-cloud-service-usage')\n",
    "    ! pip install google-cloud-service-usage -q\n",
    "try:\n",
    "    import google.cloud.artifactregistry_v1 \n",
    "except ImportError:\n",
    "    print('You need to pip install google-cloud-artifact-registry')\n",
    "    ! pip install google-cloud-artifact-registry -q\n",
    "try:\n",
    "    import google.cloud.devtools.cloudbuild\n",
    "except ImportError:\n",
    "    print(\"You need to pip install google-cloud-build\")\n",
    "    !pip install google-cloud-build\n",
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown as md\n",
    "from google.cloud import service_usage_v1\n",
    "from google.cloud.devtools import cloudbuild_v1\n",
    "from google.cloud import artifactregistry_v1\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb11476-ec37-4d74-89ff-b1314fd2b488",
   "metadata": {},
   "source": [
    "# Set up environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4941f364-02ea-46d7-9375-8cda6a631a53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project = !gcloud config get-value project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d5ce418-5c60-4202-9e0a-3e4e381518f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = project[0]\n",
    "REGION = 'australia-southeast1'\n",
    "EXPERIMENT = '04'\n",
    "SERIES = '04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa41d30b-0104-4f1b-abaa-04a917b99cca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'media_campaign_cost'\n",
    "BQ_TABLE = 'mcc_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4f4de5ed-825c-45c3-abb1-2ee355326764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_IMAGE = 'us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu113.py310'\n",
    "#DEPLOY_IMAGE = 'us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-23:latest'\n",
    "\n",
    "DEPLOY_IMAGE = 'australia-southeast1-docker.pkg.dev/my-project-media-campaign-cost/my-project-media-campaign-cost4/04_trainer:latest'\n",
    "TRAIN_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/scikit-learn-cpu.0-23:latest'\n",
    "TRAIN_COMPUTE = 'n1-standard-4'\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cef5be44-0394-450d-b2ae-cb451a084d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TIMESTAMP =datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{SERIES}/{EXPERIMENT}\"\n",
    "DIR = f\"temp/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a07850a1-1eba-4985-9333-fd0ee89529b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)'\n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2a0ad8b-d2d9-4fd7-971b-8b14a58ec39f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "47c15f4e-c018-4364-a38d-4925f0aa606c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Experiment Tracking\n",
    "FRAMEWORK = 'sklearn'\n",
    "TASK = 'regression'\n",
    "MODEL_TYPE = 'ensemble'\n",
    "EXPERIMENT_NAME = f'experiment-{SERIES}-{EXPERIMENT}-{FRAMEWORK}-{TASK}-{MODEL_TYPE}'\n",
    "RUN_NAME = f'run-{TIMESTAMP}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "547efbf8-32b9-4c57-a5d7-d250a375af83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a list of clients \n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bq = bigquery.Client(project=PROJECT_ID)\n",
    "gcs = storage.Client(project=PROJECT_ID)\n",
    "su_client = service_usage_v1.ServiceUsageClient()\n",
    "ar_client = artifactregistry_v1.ArtifactRegistryClient()\n",
    "cb_client = cloudbuild_v1.CloudBuildClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a1ffb-fab7-40fd-b9ec-1d6a86b48305",
   "metadata": {},
   "source": [
    "# Set up Vertex AI experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcc50bb1-fcce-4a18-8931-64afb0aac563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(experiment=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6300d8ec-08f4-4c05-a494-db4894d3ffa2",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "edb1bae1-0732-4265-b0e4-cbedfe49c723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "\n",
       "#import packages\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.model_selection import cross_val_score\n",
       "from sklearn.preprocessing import StandardScaler\n",
       "from sklearn.preprocessing import OneHotEncoder, TargetEncoder\n",
       "from sklearn.pipeline import Pipeline, make_pipeline\n",
       "from sklearn.compose import ColumnTransformer\n",
       "from sklearn.metrics import mean_squared_log_error\n",
       "from sklearn.ensemble import VotingRegressor\n",
       "from catboost import CatBoostRegressor\n",
       "from xgboost import XGBRegressor\n",
       "from lightgbm import LGBMRegressor\n",
       "import pandas as pd\n",
       "import numpy as np\n",
       "import pickle\n",
       "from google.cloud import bigquery \n",
       "from google.cloud import aiplatform\n",
       "from google.cloud import storage\n",
       "import hypertune\n",
       "import argparse\n",
       "import os\n",
       "import sys\n",
       "# local parameters\n",
       "parser =  argparse.ArgumentParser()\n",
       "parser.add_argument('--project_id',dest ='project_id',type=str)\n",
       "parser.add_argument('--bq_project',dest ='bq_project', type=str)\n",
       "parser.add_argument('--bq_dataset',dest ='bq_dataset', type=str)\n",
       "parser.add_argument('--bq_table', dest ='bq_table',type=str)\n",
       "parser.add_argument('--region', dest = 'region', type=str)\n",
       "parser.add_argument('--experiment', dest='experiment',type=str)\n",
       "parser.add_argument('--series', dest='series', type=str)\n",
       "parser.add_argument('--experiment_name',dest='experiment_name',type=str)\n",
       "parser.add_argument('--run_name', dest = 'run_name', type = str)\n",
       "# xgb&lightgbm\n",
       "parser.add_argument('--x_seed', dest = 'x_seed', type = int)\n",
       "parser.add_argument('--l_seed', dest = 'l_seed', type = int)\n",
       "parser.add_argument('--x_objective', dest='x_objective', type = str)\n",
       "parser.add_argument('--l_objective', dest='l_objective', type = str)\n",
       "parser.add_argument('--x_max_depth', dest='x_max_depth',type=int)\n",
       "parser.add_argument('--l_max_depth', dest='l_max_depth',type=int)\n",
       "#xgb&cat\n",
       "parser.add_argument('--x_grow_policy', dest='x_grow_policy', type = str)\n",
       "parser.add_argument('--c_grow_policy', dest='c_grow_policy', type = str)\n",
       "#lightgbm & cat\n",
       "parser.add_argument('--l_learning_rate', dest='l_learning_rate', type = float)\n",
       "parser.add_argument('--c_learning_rate', dest='c_learning_rate', type = float)\n",
       "# xgb \n",
       "parser.add_argument('--eval_metric', dest='eval_metric', type = str)\n",
       "parser.add_argument('--tree_method', dest='tree_method', type = str)\n",
       "parser.add_argument('--eta', dest=\"eta\", type=float)\n",
       "parser.add_argument('--alpha', dest='alpha', type=float)\n",
       "#lighgbm\n",
       "parser.add_argument('--metric', dest='metric', type = str)\n",
       "parser.add_argument('--feature_fraction', dest='feature_fraction', type=float)\n",
       "parser.add_argument('--bagging_fraction', dest='bagging_fraction', type=float)\n",
       "parser.add_argument('--verbose', dest='verbose', type=int)\n",
       "parser.add_argument('--num_leaves', dest='num_leaves', type = int)\n",
       "parser.add_argument('--lambda_l1', dest='lambda_l1', type=float)\n",
       "#catboost\n",
       "parser.add_argument('--random_seed', dest = 'random_seed', type = int)\n",
       "parser.add_argument('--loss_function', dest='loss_function', type=str)\n",
       "parser.add_argument('--depth', dest='depth', type = int)\n",
       "parser.add_argument('--iterations', dest='iterations',type=int)\n",
       "parser.add_argument('--l2_leaf_reg', dest='l2_leaf_reg', type=float)\n",
       "args = parser.parse_args()\n",
       "# create clients\n",
       "bq =  bigquery.Client(project=args.project_id)\n",
       "aiplatform.init(project = args.project_id, location = args.region)\n",
       "#vertex ai experiment \n",
       "if args.run_name in [run.name for run in aiplatform.ExperimentRun.list(experiment = args.experiment_name)]:\n",
       "    expRun = aiplatform.ExperimentRun(run_name = args.run_name, experiment = args.experiment_name)\n",
       "else:\n",
       "    expRun = aiplatform.ExperimentRun.create(run_name = args.run_name, experiment = args.experiment_name)\n",
       "expRun.log_params({'experiment':args.experiment, 'series':args.series, 'project_id': args.project_id})\n",
       "expRun.log_params({'data_source':f\"bq://{args.bq_project}.{args.bq_dataset}.{args.bq_table}\"})\n",
       "# extract data from bigquery table\n",
       "# drop recyclable_packge and low_fat due to the feature importance we found in previous hyperparameter tuning job.\n",
       "# feature engineering: creat home_children_ratio, drop prepared_food since high-correlation to salad_bar\n",
       "query = f\"SELECT store_sales_in_millions_, unit_sales_in_millions_, total_children-num_children_at_home AS independent_children,gross_weight, avg_cars_at_home_approx__1, units_per_case, store_sqft, coffee_bar+video_store+salad_bar+florist AS store_score, cost FROM `{args.bq_project}.{args.bq_dataset}.{args.bq_table}`\"\n",
       "df = bq.query(query).to_dataframe()\n",
       "# extract target variable and explainatory variables\n",
       "y = df['cost']\n",
       "x = df.drop('cost', axis=\"columns\")\n",
       "# data preprocessing \n",
       "num_attrib = [\"independent_children\",\"avg_cars_at_home_approx__1\", \"store_sqft\", \"store_score\"]\n",
       "preprocess =  ColumnTransformer([(\"numerical\", TargetEncoder(), num_attrib)],remainder='passthrough')\n",
       "x_processed = preprocess.fit_transform(x,y)\n",
       "# split data into train and test data sets\n",
       "x_train,x_test,y_train,y_test =  train_test_split(x_processed, y, train_size = 0.8, test_size = 0.2, random_state=50)\n",
       "#xgb_model parameters\n",
       "xgb_params = {\n",
       "    'seed': args.x_seed,\n",
       "    'objective': args.x_objective,\n",
       "    'eval_metric': args.eval_metric,\n",
       "    'eta': args.eta,\n",
       "    'max_depth': args.x_max_depth,\n",
       "    'alpha': args.alpha,\n",
       "    'tree_method': args.tree_method,\n",
       "    'grow_policy': args.x_grow_policy\n",
       "}\n",
       "#lgbm_model parameters\n",
       "lgbm_params = {\n",
       "    'seed': args.l_seed,\n",
       "    'objective': args.l_objective,\n",
       "    'metric': args.metric,\n",
       "    'learning_rate': args.l_learning_rate,\n",
       "    'max_depth': args.l_max_depth,\n",
       "    'lambda_l1': args.lambda_l1,\n",
       "    'num_leaves': args.num_leaves,\n",
       "    'bagging_fraction': args.bagging_fraction,\n",
       "    'feature_fraction': args.feature_fraction,\n",
       "    'verbose': args.verbose\n",
       "}\n",
       "#catboost_model parameters\n",
       "catboost_params = {\n",
       "    'random_seed': args.random_seed,\n",
       "    'learning_rate': args.c_learning_rate,\n",
       "    'iterations': args.iterations,\n",
       "    'l2_leaf_reg': args.l2_leaf_reg,\n",
       "    'depth': args.depth,\n",
       "    'loss_function': args.loss_function,\n",
       "    'grow_policy': args.c_grow_policy,\n",
       "}\n",
       "# build model \n",
       "xgb_model = XGBRegressor(**xgb_params)\n",
       "lgbm_model = LGBMRegressor(**lgbm_params)\n",
       "cat_model = CatBoostRegressor(**catboost_params)\n",
       "ensemble_model = VotingRegressor([(\"xgb\", xgb_model),(\"lgbm\",lgbm_model),(\"catboost\",cat_model)])\n",
       "# train model \n",
       "model_ensemble = ensemble_model.fit(x_train, y_train)\n",
       "# evaluate using msle metric\n",
       "y_train_pred = model_ensemble.predict(x_train)\n",
       "train_msle = mean_squared_log_error(y_train_pred, y_train)\n",
       "y_test_pred =  model_ensemble.predict(x_test)\n",
       "test_msle = mean_squared_log_error(y_test_pred, y_test)\n",
       "expRun.log_params({\"train_msle\": train_msle, \"test_msle\": test_msle})\n",
       "# save the model\n",
       "file_name = 'ensemble_model.pkl'\n",
       "# Use predefined environment variable to establish model directionary\n",
       "model_directory = os.environ['AIP_MODEL_DIR']\n",
       "storage_path = f'/gcs/{model_directory[5:]}'+file_name\n",
       "os.makedirs(os.path.dirname(storage_path), exist_ok=True)\n",
       "# output the model save files directly to GCS destination\n",
       "with open (storage_path,'wb') as f:\n",
       "    pickle.dump(model_ensemble,f)\n",
       "expRun.log_params({'model.save': storage_path})\n",
       "expRun.end_run()\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have a look at the training python script\n",
    "script_path = './trainer/ensemble.py'\n",
    "with open(script_path, 'r') as file:\n",
    "    data = file.read()\n",
    "md(f\"```python\\n\\n{data}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafe6ac9-dcd1-4995-a584-6d4934776e59",
   "metadata": {},
   "source": [
    "# Create a custom container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "998a24f9-dd77-4a3c-9b81-0709d26398c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the source path in google cloud storage\n",
    "bucket = gcs.lookup_bucket(BUCKET)\n",
    "if not bucket:\n",
    "    gcs.bucket(BUCKET).create(location=REGION)\n",
    "SOURCEPATH = f'{SERIES}/{EXPERIMENT}/training' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "14bcf2bd-3f23-4ba9-b83a-38d27101403a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# upload training code to google cloud storage\n",
    "blob = storage.Blob(f'{SOURCEPATH}/{EXPERIMENT}_trainer/train.py', bucket=gcs.bucket(BUCKET))\n",
    "blob.upload_from_filename(script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a0e8c973-2593-4f6e-90b8-96685b49b13e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create requirement file for docker file\n",
    "requirements = f\"\"\" google-cloud-aiplatform\n",
    "protobuf\n",
    "db-dtypes>=1.0.0\n",
    "google-auth>=2.6.0\n",
    "google-cloud-bigquery>=3.0.1\n",
    "cloudml-hypertune\n",
    "xgboost\n",
    "lightgbm\n",
    "catboost\n",
    "\"\"\"\n",
    "blob = storage.Blob(f'{SOURCEPATH}/requirements.txt', bucket=gcs.bucket(BUCKET))\n",
    "blob.upload_from_string(requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d1c5bac8-5664-4ad9-90c9-33242f9a110d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the Dockerfile and upload to gcs\n",
    "dockerfile = f'''\n",
    "FROM {BASE_IMAGE}\n",
    "WORKDIR /training\n",
    "# copy requirements and install them\n",
    "COPY requirements.txt ./\n",
    "RUN pip install --no-cache-dir --upgrade pip \\\n",
    "  && pip install --no-cache-dir -r requirements.txt\n",
    "## Copies the trainer code to the docker image\n",
    "COPY {EXPERIMENT}_trainer/* ./{EXPERIMENT}_trainer/\n",
    "## Sets up the entry point to invoke the trainer\n",
    "ENTRYPOINT [\"python\", \"-m\", \"{EXPERIMENT}_trainer.train\"]\n",
    "'''\n",
    "blob = storage.Blob(f'{SOURCEPATH}/Dockerfile', bucket=gcs.bucket(BUCKET))\n",
    "blob.upload_from_string(dockerfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "95a8ec72-ac56-4daf-8635-9fda5a486aee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved existing repo:projects/my-project-media-campaign-cost/locations/australia-southeast1/repositories/my-project-media-campaign-cost4\n"
     ]
    }
   ],
   "source": [
    "## create docker image repository \n",
    "docker_repo = None\n",
    "for repo in ar_client.list_repositories(parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"):\n",
    "    if repo.labels['experiment']==EXPERIMENT:\n",
    "        docker_repo = repo\n",
    "        print(f'Retrieved existing repo:{docker_repo.name}')\n",
    "if not docker_repo:\n",
    "    operation = ar_client.create_repository(\n",
    "    request = artifactregistry_v1.CreateRepositoryRequest(\n",
    "        parent = f'projects/{PROJECT_ID}/locations/{REGION}',\n",
    "        repository_id =f'{PROJECT_ID}4',\n",
    "        repository = artifactregistry_v1.Repository(\n",
    "            description=f'A repository for the {EXPERIMENT} experiment',\n",
    "            name = f'{PROJECT_ID}',\n",
    "            format_ = artifactregistry_v1.Repository.Format.DOCKER,\n",
    "            labels = {'series':SERIES, 'experiment':EXPERIMENT}\n",
    "    )\n",
    "    )\n",
    "    )\n",
    "    print (\"Creating Repository ...\")\n",
    "    docker_repo = operation.result()\n",
    "    print(f'Complete creating repo: {docker_repo.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b22473d4-ab44-4090-9b00-16be258cdcd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('projects/my-project-media-campaign-cost/locations/australia-southeast1/repositories/my-project-media-campaign-cost4',\n",
       " 'DOCKER')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docker_repo.name, docker_repo.format_.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f6043a23-d5a5-4965-a365-c203f0ae7d1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REPOSITORY = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{docker_repo.name.split('/')[-1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "bce62ec3-a21b-424e-a902-824da27de2a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Status.SUCCESS: 3>,\n",
       " images: \"australia-southeast1-docker.pkg.dev/my-project-media-campaign-cost/my-project-media-campaign-cost4/04_trainer\")"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup the build config with empty list of steps - these will be added sequentially\n",
    "build = cloudbuild_v1.Build(\n",
    "    steps = []\n",
    ")\n",
    "# retrieve the source\n",
    "build.steps.append(\n",
    "    {\n",
    "        'name': 'gcr.io/cloud-builders/gsutil',\n",
    "        'args': ['cp', '-r', f'gs://{PROJECT_ID}/{SOURCEPATH}/*','/workspace']\n",
    "    }\n",
    ")\n",
    "# docker build\n",
    "build.steps.append(\n",
    "    {\n",
    "        'name': 'gcr.io/cloud-builders/docker',\n",
    "        'args': ['build', '-t', f'{REPOSITORY}/{EXPERIMENT}_trainer','/workspace']\n",
    "    }    \n",
    ")\n",
    "\n",
    "# docker push\n",
    "build.images = [f\"{REPOSITORY}/{EXPERIMENT}_trainer\"]\n",
    "\n",
    "\n",
    "\n",
    "operation = cb_client.create_build(\n",
    "    project_id = PROJECT_ID,\n",
    "    build = build\n",
    ")\n",
    "\n",
    "response = operation.result()\n",
    "response.status, response.artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c4e07cef-bb52-4e2c-884b-78cb3fc89f03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#xgb&lgbm\n",
    "X_SEED = '50'\n",
    "L_SEED = '50'\n",
    "X_OBJECTIVE = 'reg:squaredlogerror'\n",
    "L_OBJECTIVE = 'regression'\n",
    "X_MAX_DEPTH = '10'\n",
    "L_MAX_DEPTH = '20'\n",
    "#xgb&catboot\n",
    "X_GROW_POLICY = 'lossguide'\n",
    "C_GROW_POLICY = 'Lossguide'\n",
    "#lgbm&cat\n",
    "L_LEARNING_RATE = '0.1726402706922235'\n",
    "C_LEARNING_RATE='0.30403279991806864'\n",
    "#xgb\n",
    "EVAL_METRIC = 'rmsle'\n",
    "TREE_METHOD = 'hist'\n",
    "ETA = '0.6877740759969978'\n",
    "ALPHA = '0.054789458485290723'\n",
    "#lgbm\n",
    "METRIC = 'mse'\n",
    "FEATURE_FRACTION = '0.9'\n",
    "BAGGING_FRACTION = '0.7'\n",
    "VERBOSE='-1' \n",
    "NUMBER_LEAVES = '40'\n",
    "LAMBDA_L1 = '2.0'\n",
    "#cat\n",
    "RANDOM_SEED = '50'\n",
    "LOSS_FUNCTION = 'RMSE'\n",
    "DEPTH = '10'\n",
    "ITERATIONS = '100'\n",
    "L2_LEAF_REG = '2.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e19557e3-a243-440d-9ef9-de0f87cade32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CMDARGS = [\n",
    "    \"--project_id=\" + PROJECT_ID,\n",
    "    \"--bq_project=\" + BQ_PROJECT,\n",
    "    \"--bq_dataset=\" + BQ_DATASET,\n",
    "    \"--bq_table=\" + BQ_TABLE,\n",
    "    \"--region=\" + REGION,\n",
    "    \"--experiment=\" + EXPERIMENT,\n",
    "    \"--series=\" + SERIES,\n",
    "    \"--experiment_name=\" + EXPERIMENT_NAME,\n",
    "    \"--run_name=\" + RUN_NAME,\n",
    "    \"--x_seed=\" + X_SEED,\n",
    "    \"--l_seed=\" + L_SEED,\n",
    "    \"--x_objective=\" + X_OBJECTIVE,\n",
    "    \"--l_objective=\"+ L_OBJECTIVE,\n",
    "    \"--x_max_depth=\" + X_MAX_DEPTH,\n",
    "    \"--l_max_depth=\"+ L_MAX_DEPTH,\n",
    "    \"--x_grow_policy=\" + X_GROW_POLICY,\n",
    "    \"--c_grow_policy=\" + C_GROW_POLICY,\n",
    "    \"--l_learning_rate=\" + L_LEARNING_RATE,\n",
    "    \"--c_learning_rate=\" + C_LEARNING_RATE,\n",
    "    \"--eval_metric=\"+ EVAL_METRIC,\n",
    "    \"--tree_method=\"+ TREE_METHOD,\n",
    "    \"--eta=\" + ETA,\n",
    "    \"--alpha=\" + ALPHA,\n",
    "    \"--metric=\" + METRIC,\n",
    "    \"--feature_fraction=\" + FEATURE_FRACTION,\n",
    "    \"--bagging_fraction=\" + BAGGING_FRACTION,\n",
    "    \"--verbose=\" + VERBOSE,\n",
    "    \"--num_leaves=\"+ NUMBER_LEAVES,\n",
    "    \"--lambda_l1=\"+LAMBDA_L1,\n",
    "    \"--random_seed=\" + RANDOM_SEED,\n",
    "    \"--loss_function=\" + LOSS_FUNCTION,\n",
    "    \"--depth=\" + DEPTH, \n",
    "    \"--iterations=\"+ITERATIONS,\n",
    "    \"--l2_leaf_reg=\"+L2_LEAF_REG,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "74f8ba73-8fe5-4ac2-918b-04fe00e529b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--project_id=my-project-media-campaign-cost',\n",
       " '--bq_project=my-project-media-campaign-cost',\n",
       " '--bq_dataset=media_campaign_cost',\n",
       " '--bq_table=mcc_train',\n",
       " '--region=australia-southeast1',\n",
       " '--experiment=04',\n",
       " '--series=04',\n",
       " '--experiment_name=experiment-04-04-sklearn-regression-ensemble',\n",
       " '--run_name=run-20231229122112',\n",
       " '--x_seed=50',\n",
       " '--l_seed=50',\n",
       " '--x_objective=reg:squaredlogerror',\n",
       " '--l_objective=regression',\n",
       " '--x_max_depth=10',\n",
       " '--l_max_depth=20',\n",
       " '--x_grow_policy=lossguide',\n",
       " '--c_grow_policy=Lossguide',\n",
       " '--l_learning_rate=0.1726402706922235',\n",
       " '--c_learning_rate=0.30403279991806864',\n",
       " '--eval_metric=rmsle',\n",
       " '--tree_method=hist',\n",
       " '--eta=0.6877740759969978',\n",
       " '--alpha=0.054789458485290723',\n",
       " '--metric=mse',\n",
       " '--feature_fraction=0.9',\n",
       " '--bagging_fraction=0.7',\n",
       " '--verbose=-1',\n",
       " '--num_leaves=40',\n",
       " '--lambda_l1=2.0',\n",
       " '--random_seed=50',\n",
       " '--loss_function=RMSE',\n",
       " '--depth=10',\n",
       " '--iterations=100',\n",
       " '--l2_leaf_reg=2.0']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMDARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "234f80dd-62c5-4fa2-99a6-f20d7a5d4505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MACHINE_SPEC = {\n",
    "    \"machine_type\": TRAIN_COMPUTE,\n",
    "    \"accelerator_count\": 0\n",
    "}\n",
    "\n",
    "WORKER_POOL_SPEC = [\n",
    "    {\n",
    "        \"replica_count\":1,\n",
    "        \"machine_spec\":MACHINE_SPEC,\n",
    "        \"container_spec\":{\n",
    "            \"image_uri\": f\"{REPOSITORY}/{EXPERIMENT}_trainer\",\n",
    "            \"args\":CMDARGS,\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "86e8222c-4b8c-4f40-9466-1688cadd4269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customJob = aiplatform.CustomJob(\n",
    "    display_name = f'{SERIES}_{EXPERIMENT}_{TIMESTAMP}',\n",
    "    worker_pool_specs = WORKER_POOL_SPEC,\n",
    "    base_output_dir = f\"{URI}/models/{TIMESTAMP}\",\n",
    "    staging_bucket = f\"{URI}/models/{TIMESTAMP}\",\n",
    "    labels = {'series': f'{SERIES}', 'experiment':f'{EXPERIMENT}','experiment_name':f'{EXPERIMENT_NAME}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "68809ffa-7a32-45bc-b007-176cf6340397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CustomJob\n",
      "CustomJob created. Resource name: projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760\n",
      "To use this CustomJob in another session:\n",
      "custom_job = aiplatform.CustomJob.get('projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760')\n",
      "View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/australia-southeast1/training/1231464018225397760?project=683212519680\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "CustomJob run completed. Resource name: projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tuningJob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[191], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m customJob\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m      2\u001b[0m     service_account \u001b[38;5;241m=\u001b[39m SERVICE_ACCOUNT\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtuningJob\u001b[49m\u001b[38;5;241m.\u001b[39mresource_name, tuningJob\u001b[38;5;241m.\u001b[39mdisplay_name\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tuningJob' is not defined"
     ]
    }
   ],
   "source": [
    "customJob.run(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "23e08256-2e32-4fac-a7cb-5ed559ec8681",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('projects/683212519680/locations/australia-southeast1/customJobs/1231464018225397760',\n",
       " '04_04_20231229122112')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customJob.resource_name, customJob.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "dd085b6f-2f22-4d96-95bb-7721ed81652e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Custom Job here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/australia-southeast1/training/1231464018225397760/cpu?cloudshell=false&project=my-project-media-campaign-cost\n"
     ]
    }
   ],
   "source": [
    "job_link = f\"https://console.cloud.google.com/vertex-ai/locations/{REGION}/training/{customJob.resource_name.split('/')[-1]}/cpu?cloudshell=false&project={PROJECT_ID}\"\n",
    "\n",
    "print(f'Review the Custom Job here:\\n{job_link}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f16fc8-9250-4c18-b0a4-ff83d364026f",
   "metadata": {},
   "source": [
    "# Upload the model to repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ec217ac0-b1c5-45dc-884a-e12742eba5fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new model, creating in model registry\n",
      "Creating Model\n",
      "Create Model backing LRO: projects/683212519680/locations/australia-southeast1/models/model_04_04/operations/7024508210488803328\n",
      "Model created. Resource name: projects/683212519680/locations/australia-southeast1/models/model_04_04@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/683212519680/locations/australia-southeast1/models/model_04_04@1')\n"
     ]
    }
   ],
   "source": [
    "modelmatch = aiplatform.Model.list(filter = f'display_name={SERIES}_{EXPERIMENT} AND labels.series={SERIES} AND labels.experiment={EXPERIMENT}')\n",
    "\n",
    "upload_model = True\n",
    "if modelmatch:\n",
    "    print(\"Model Already in Registry:\")\n",
    "    if RUN_NAME in modelmatch[0].version_aliases:\n",
    "        print(\"This version already loaded, no action taken.\")\n",
    "        upload_model = False\n",
    "        model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "    else:\n",
    "        print('Loading model as new default version.')\n",
    "        parent_model = modelmatch[0].resource_name\n",
    "\n",
    "else:\n",
    "    print('This is a new model, creating in model registry')\n",
    "    parent_model = ''\n",
    "\n",
    "if upload_model:\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name = f'{SERIES}_{EXPERIMENT}',\n",
    "        model_id = f'model_{SERIES}_{EXPERIMENT}',\n",
    "        parent_model =  parent_model,\n",
    "        serving_container_image_uri = DEPLOY_IMAGE,\n",
    "        artifact_uri = \"gs://my-project-media-campaign-cost/04/04/models/20231229122112/model\",\n",
    "        is_default_version = True,\n",
    "        version_aliases = [RUN_NAME],\n",
    "        version_description = RUN_NAME,\n",
    "        labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'}        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a07227c1-f118-4817-8c12-328f10a36a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expRun = aiplatform.ExperimentRun(run_name = RUN_NAME, experiment = EXPERIMENT_NAME)\n",
    "\n",
    "expRun.log_params({\n",
    "    'model.uri': model.uri,\n",
    "    'model.display_name': model.display_name,\n",
    "    'model.name': model.name,\n",
    "    'model.resource_name': model.resource_name,\n",
    "    'model.version_id': model.version_id,\n",
    "    'model.versioned_resource_name': model.versioned_resource_name,\n",
    "    'customJobs.display_name': customJob.display_name,\n",
    "    'customJobs.resource_name': customJob.resource_name,\n",
    "    'customJobs.link': job_link\n",
    "})\n",
    "expRun.update_state(state = aiplatform.gapic.Execution.State.COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc984157-b546-4970-ae08-32dd25a28bd4",
   "metadata": {},
   "source": [
    "# Review the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a2d9ff40-854c-4441-b774-4dc08a776465",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>run_type</th>\n",
       "      <th>state</th>\n",
       "      <th>param.customJobs.display_name</th>\n",
       "      <th>param.experiment</th>\n",
       "      <th>param.customJobs.link</th>\n",
       "      <th>param.project_id</th>\n",
       "      <th>param.model.uri</th>\n",
       "      <th>param.customJobs.resource_name</th>\n",
       "      <th>param.data_source</th>\n",
       "      <th>param.model.display_name</th>\n",
       "      <th>param.model.versioned_resource_name</th>\n",
       "      <th>param.model.save</th>\n",
       "      <th>param.model.name</th>\n",
       "      <th>param.model.resource_name</th>\n",
       "      <th>param.test_msle</th>\n",
       "      <th>param.model.version_id</th>\n",
       "      <th>param.series</th>\n",
       "      <th>param.train_msle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experiment-04-04-sklearn-regression-ensemble</td>\n",
       "      <td>run-20231229122112</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>04_04_20231229122112</td>\n",
       "      <td>04</td>\n",
       "      <td>https://console.cloud.google.com/vertex-ai/loc...</td>\n",
       "      <td>my-project-media-campaign-cost</td>\n",
       "      <td>gs://my-project-media-campaign-cost/04/04/mode...</td>\n",
       "      <td>projects/683212519680/locations/australia-sout...</td>\n",
       "      <td>bq://my-project-media-campaign-cost.media_camp...</td>\n",
       "      <td>04_04</td>\n",
       "      <td>projects/683212519680/locations/australia-sout...</td>\n",
       "      <td>/gcs/my-project-media-campaign-cost/04/04/mode...</td>\n",
       "      <td>model_04_04</td>\n",
       "      <td>projects/683212519680/locations/australia-sout...</td>\n",
       "      <td>0.092623</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>0.09135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                experiment_name            run_name  \\\n",
       "0  experiment-04-04-sklearn-regression-ensemble  run-20231229122112   \n",
       "\n",
       "               run_type     state param.customJobs.display_name  \\\n",
       "0  system.ExperimentRun  COMPLETE          04_04_20231229122112   \n",
       "\n",
       "  param.experiment                              param.customJobs.link  \\\n",
       "0               04  https://console.cloud.google.com/vertex-ai/loc...   \n",
       "\n",
       "                 param.project_id  \\\n",
       "0  my-project-media-campaign-cost   \n",
       "\n",
       "                                     param.model.uri  \\\n",
       "0  gs://my-project-media-campaign-cost/04/04/mode...   \n",
       "\n",
       "                      param.customJobs.resource_name  \\\n",
       "0  projects/683212519680/locations/australia-sout...   \n",
       "\n",
       "                                   param.data_source param.model.display_name  \\\n",
       "0  bq://my-project-media-campaign-cost.media_camp...                    04_04   \n",
       "\n",
       "                 param.model.versioned_resource_name  \\\n",
       "0  projects/683212519680/locations/australia-sout...   \n",
       "\n",
       "                                    param.model.save param.model.name  \\\n",
       "0  /gcs/my-project-media-campaign-cost/04/04/mode...      model_04_04   \n",
       "\n",
       "                           param.model.resource_name  param.test_msle  \\\n",
       "0  projects/683212519680/locations/australia-sout...         0.092623   \n",
       "\n",
       "  param.model.version_id param.series  param.train_msle  \n",
       "0                      1           04           0.09135  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = aiplatform.Experiment(experiment_name = EXPERIMENT_NAME)\n",
    "exp.get_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e383b-68c3-49b0-b008-28af467f08ee",
   "metadata": {},
   "source": [
    "# Retrieve or create the end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e47bb620-7ded-4158-8264-7fa2f532ae70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/683212519680/locations/australia-southeast1/endpoints/6048360687837642752/operations/4043072480611401728\n",
      "Endpoint created. Resource name: projects/683212519680/locations/australia-southeast1/endpoints/6048360687837642752\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/683212519680/locations/australia-southeast1/endpoints/6048360687837642752')\n",
      "Endpoint Created: projects/683212519680/locations/australia-southeast1/endpoints/6048360687837642752\n"
     ]
    }
   ],
   "source": [
    "endpoints = aiplatform.Endpoint.list(filter = f\"labels.series={SERIES}\")\n",
    "if endpoints:\n",
    "    endpoint = endpoints[0]\n",
    "    print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "else:\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name = f\"{SERIES}\",\n",
    "        labels = {'series' : f\"{SERIES}\"}    \n",
    "    )\n",
    "    print(f\"Endpoint Created: {endpoint.resource_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2d9668c4-2d14-4f10-ba69-b25822ca9f75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Model object at 0x7fbe2c8a65c0> \n",
       "resource name: projects/683212519680/locations/australia-southeast1/models/model_04_04"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "80401d44-fbc2-4e84-8d21-6b441817df66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'04_04'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8d9b74-d230-4696-867e-cc6285439f72",
   "metadata": {},
   "source": [
    "# Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b81e2813-24d2-4607-b353-9c80c23384e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost \n",
    "import lightgbm\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5885d31-625a-49b7-acb5-9de9d7f87f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.deploy(\n",
    "        model = model,\n",
    "        deployed_model_display_name = model.display_name,\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = DEPLOY_COMPUTE,\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de35c9ad-40dd-425a-bf0b-0ec01f4e6d02",
   "metadata": {},
   "outputs": [],
   "source": [
    " endpoint.undeploy(deployed_model_id = deployed_model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35733add-7e0f-426e-a3b6-9ac0912c2755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m114"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
